# -*- coding: utf-8 -*-
""" settings """

import os
import logging

import torch
from gtorch_utils.segmentation import torchmetrics

from nns.utils.metrics import MetricItem

###############################################################################
#                                GENERAL CONFIG                               #
###############################################################################

BASE_PATH = os.getenv("HOME")
PROJECT_PATH = os.path.join(BASE_PATH, '<path to your project>')
# https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html#all-together-automatic-mixed-precision
USE_AMP = False  # Automatic Mixed Precision
LOG_LEVEL = logging.INFO
CUDA = True
MULTIGPUS = True
PATCH_REPLICATION_CALLBACK = True
COTRAINING = True
# ORIGINAL_MASKS: if True the CoTraining will merge the original masks
#                 (not the co-training masks) with the new predictions;
#                 otherwise, the co-training masks will be used (normal workflow)
ORIGINAL_MASKS = True
# Metrics to be used by ModelMGR and CoTraining
METRICS = [
    MetricItem(torchmetrics.DiceCoefficient(), main=True),
    MetricItem(torchmetrics.Specificity()),
    # MetricItem(torchmetrics.Recall()),
    MetricItem(torchmetrics.Accuracy()),
    MetricItem(torchmetrics.BalancedAccuracy()),
]


###############################################################################
#                                     NNS                                     #
###############################################################################

DIR_CHECKPOINTS = os.path.join(PROJECT_PATH, 'checkpoints')
PLOT_DIRECTORY = os.path.join(PROJECT_PATH, 'plots')

###############################################################################
#                                    CONSEP                                    #
###############################################################################
if CUDA == MULTIGPUS == True and torch.cuda.is_available():
    NUM_GPUS = torch.cuda.device_count()
else:
    NUM_GPUS = 1  # When working with only 1 GPU or CPU

PATCH_SIZE = (540, 540)
PATCH_STEP_SIZE = (164, 164)
# crops are extracted from the patches
CROP_IMG_SHAPE = (270, 270)
CROP_MASK_SHAPE = (270, 270)  # (80, 80)
BATCH_SIZE = 16
TOTAL_BATCH_SIZE = BATCH_SIZE * NUM_GPUS
NUM_WORKERS = 16  # set it to 0 when debugging the dataset
CREATEDATASET_SAVING_PATH = 'consep_dataset'

###############################################################################
#                                   DATASETS                                  #
###############################################################################

# CoNSeP (dataset created after running consep.processors.offline.CreateDataset)
CONSEP_TRAIN_PATH = os.path.join(PROJECT_PATH, CREATEDATASET_SAVING_PATH, 'train')
CONSEP_VAL_PATH = os.path.join(PROJECT_PATH, CREATEDATASET_SAVING_PATH, 'val')
CONSEP_TEST_PATH = ''

###############################################################################
#                                  BACKBONES                                  #
###############################################################################

BACKBONES_BN_MOM = .1
BACKBONES_MEAN = (.485, .456, .406)
BACKBONES_STD = (.229, .224, .225)
BACKBONES_DIR_CHECKPOINTS = os.path.join(DIR_CHECKPOINTS, 'backbones')

# NOTE: If using xception, then manually download it from
# https://drive.google.com/file/d/1_j_mE07tiV24xXOJw4XDze0-a0NAhNVi/view
# and place it in the right directory

BACKBONES_MODEL_URLS = {
    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
    'resnet50': 'https://s3.us-west-1.wasabisys.com/encoding/models/resnet50s-a75c83cf.zip',
    'resnet101': 'https://s3.us-west-1.wasabisys.com/encoding/models/resnet101s-03a0f310.zip',
    'resnet152': 'https://s3.us-west-1.wasabisys.com/encoding/models/resnet152s-36670e8b.zip',
    'xception': os.path.join(BACKBONES_DIR_CHECKPOINTS, 'xception_pytorch_imagenet.pth'),
}

###############################################################################
#                                  DEBUGGING                                  #
###############################################################################

DEBUG = False

if DEBUG:
    # Add any extra debugging behaviour here
    LOG_LEVEL = logging.DEBUG
    # MULTIGPUS = False
    # NUM_GPUS = 1
    # TOTAL_BATCH_SIZE = BATCH_SIZE * NUM_GPUS
    NUM_WORKERS = 0  # necessary to properly use the breakpoints
